# ğŸš€ Nitro Project - Industrial Predictive Monitoring System

## ğŸ“‹ Table of Contents
1. [Features](#-features)
2. [System Architecture](#-system-architecture)
3. [Services and Ports](#-services-and-ports)
4. [Quick Start](#-quick-start)
5. [Project Structure](#-project-structure)
6. [Analysis Notebooks](#-analysis-notebooks)
7. [Data Flow](#-data-flow)
8. [Implemented Technologies](#-implemented-technologies)
9. [Maintenance](#-maintenance)
10. [Troubleshooting](#-troubleshooting)

## âœ¨ Features

- ğŸ“Š **Real-time data ingestion** with Kafka Producer
- âš¡ **Distributed processing** with Spark Streaming
- ğŸ”§ **Intelligent orchestration** with Apache Airflow
- ğŸ’¾ **Scalable storage** in PostgreSQL and MinIO
- ğŸ¤– **Advanced MLOps** with MLflow and SHAP
- ğŸ“ˆ **Professional visualization** with Streamlit and Grafana
- ğŸ““ **Comprehensive analysis** with specialized notebooks
- ğŸ” **Real-time monitoring** with interactive dashboards

## ğŸ—ï¸ System Architecture

```mermaid
graph LR
A[Kafka Producer] --> B[Kafka Cluster]
B --> C[Spark Processor]
C --> D[(PostgreSQL)]
C --> E[MinIO Storage]
D --> F[FastAPI ML Service]
E --> F
F --> G[Streamlit Dashboard]
F --> H[Grafana Monitoring]
D --> H
```

## ğŸŒ Services and Ports

| Service | URL | Port | Credentials | Status |
|----------|-----|--------|--------------|--------|
| ğŸ”§ **Airflow** | http://localhost:8080 | 8080 | admin/admin | âœ… Operational |
| âš¡ **Spark Master** | http://localhost:8081 | 8081 | - | âœ… Operational |
| ğŸ“Š **Streamlit Dashboard** | http://localhost:8501 | 8501 | - | âœ… Operational |
| ğŸ“ˆ **Grafana** | http://localhost:3000 | 3000 | admin/admin123 | âœ… Operational |
| ğŸ’¾ **MinIO Console** | http://localhost:9001 | 9001 | admin/admin12345 | âœ… Operational |
| ğŸ—„ï¸ **PostgreSQL** | localhost:5432 | 5432 | nitro_user/nitro_pass | âœ… Operational |
| ğŸš€ **FastAPI** | http://localhost:8000 | 8000 | - | âœ… Operational |
| ğŸ“¡ **Kafka** | localhost:9092 | 9092/29092 | - | âœ… Operational |

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone <your-repository>
cd proyecto-nitro

# Start all services
docker-compose up -d

# Check service status
docker-compose ps

# Start the data producer
./start-producer.sh

# Access dashboards (wait 2-3 minutes for complete initialization)
echo "Access URLs:"
echo "Airflow: http://localhost:8080"
echo "Grafana: http://localhost:3000"
echo "Streamlit: http://localhost:8501"
```

## ğŸ“ Project Structure

```
proyecto-nitro/
â”œâ”€â”€ ğŸ“Š airflow/                 # Airflow DAGs and configuration
â”œâ”€â”€ ğŸš€ api-dashboard/           # FastAPI and Streamlit
â”‚   â”œâ”€â”€ fastapi/               # ML prediction API
â”‚   â””â”€â”€ dashboards/            # Interactive dashboards
â”œâ”€â”€ ğŸ“¡ kafka-producer/          # Kafka data producer
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ kafka_producer.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ—„ï¸ minio-setup/             # MinIO bucket configuration
â”œâ”€â”€ ğŸ““ notebooks/              # Analysis and modeling
â”‚   â”œâ”€â”€ ğŸ“Š EDA.ipynb
â”‚   â”œâ”€â”€ âš™ï¸ feature_engineering.ipynb
â”‚   â”œâ”€â”€ ğŸ¤– model_training.ipynb
â”‚   â”œâ”€â”€ ğŸ” mlflow_tracking.ipynb
â”‚   â”œâ”€â”€ ğŸ“ˆ SHAP_analysis.ipynb
â”‚   â”œâ”€â”€ ğŸ“‹ reports/
â”‚   â”œâ”€â”€ ğŸ§  models/
â”‚   â””â”€â”€ ğŸ’¾ data/
â”‚       â””â”€â”€ enhanced_predictions.csv
â”œâ”€â”€ ğŸ—ƒï¸ postgres-setup/          # PostgreSQL schemas and config
â”œâ”€â”€ âš¡ python-processor/        # Spark data processor
â”œâ”€â”€ ğŸ”¥ spark-processing/       # Spark jobs
â”œâ”€â”€ ğŸ³ docker-compose.yml      # Container orchestration
â”œâ”€â”€ ğŸš€ start-producer.sh       # Startup script
â””â”€â”€ ğŸ“– README.md              # This file
```

## ğŸ““ Analysis Notebooks

| Notebook | Description | Technologies |
|----------|-------------|-------------|
| ğŸ“Š `EDA.ipynb` | Exploratory Data Analysis | Pandas, Matplotlib, Seaborn |
| âš™ï¸ `feature_engineering.ipynb` | Feature engineering | Scikit-learn, Featuretools |
| ğŸ¤– `model_training.ipynb` | Predictive model training | Scikit-learn, XGBoost, MLflow |
| ğŸ” `mlflow_tracking.ipynb` | ML experiment tracking | MLflow, Hyperopt |
| ğŸ“ˆ `SHAP_analysis.ipynb` | Model explainability | SHAP, Matplotlib |

## ğŸ”„ Data Flow

1. **Ingestion**: Kafka Producer generates simulated industrial sensor data
2. **Streaming**: Kafka publishes to `sensor_topic` with 1 partition
3. **Processing**: Spark processes data in real-time with transformations
4. **Storage**: Data persisted in PostgreSQL (structured) and MinIO (raw)
5. **Analysis**: Specialized notebooks for EDA and predictive modeling
6. **Visualization**: Real-time dashboards with Streamlit and Grafana
7. **Prediction**: FastAPI serves ML models for predictive maintenance

## ğŸ› ï¸ Implemented Technologies

### ğŸ—ï¸ Data Engineering
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)
![MinIO](https://img.shields.io/badge/MinIO-FF0019?style=for-the-badge&logo=minio&logoColor=white)

### ğŸ¤– Machine Learning
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)
![SHAP](https://img.shields.io/badge/SHAP-FF6B6B?style=for-the-badge)

### ğŸ“Š Visualization & Monitoring
![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)

### ğŸ³ Infrastructure
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Docker Compose](https://img.shields.io/badge/Docker%20Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)

## ğŸ› ï¸ Maintenance

### Useful Commands
```bash
# View logs for all services
docker-compose logs

# View specific service logs
docker-compose logs kafka
docker-compose logs spark-master

# Restart a specific service
docker-compose restart kafka-producer

# Check container status
docker-compose ps

# Access PostgreSQL
docker-compose exec postgres psql -U nitro_user -d nitro_db

# List Kafka topics
docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Scale Spark workers
docker-compose up -d --scale spark-worker=3
```

## ğŸ› Troubleshooting

### Common Issues and Solutions

| Issue | Solution |
|----------|----------|
| Kafka won't start | Check Zookeeper health: `docker-compose logs zookeeper` |
| Producer can't connect | Wait 30-60 seconds for Kafka complete initialization |
| PostgreSQL connection refused | Check logs: `docker-compose logs postgres` |
| Dashboards won't load | Wait 2-3 minutes and verify all services are UP |
| Airflow webserver error | Run: `docker-compose restart airflow` |

### Cleanup and Reinstallation
```bash
# Stop and remove all containers and volumes
docker-compose down -v

# Rebuild and start all services
docker-compose up -d --build

# Force container recreation
docker-compose up -d --force-recreate
```

## ğŸ“Š Grafana Dashboard - Recommended Configuration

To configure Grafana with your PostgreSQL data:

1. Access http://localhost:3000
2. Configure PostgreSQL data source:
   - Host: `postgres:5432`
   - Database: `nitro_db`
   - User: `nitro_user`
   - Password: `nitro_pass`
3. Import dashboards for:
   - Kafka monitoring (lag, throughput)
   - Spark performance metrics
   - ML model prediction analysis
   - Real-time sensor health status

## ğŸ“ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contribution

Contributions are welcome! 

```bash
# 1. Fork the project
# 2. Create your feature branch
git checkout -b feature/AmazingFeature

# 3. Commit your changes
git commit -m 'Add some AmazingFeature'

# 4. Push to the branch
git push origin feature/AmazingFeature

# 5. Open a Pull Request
```

## ğŸ“ Support

If you encounter issues:
1. Check the Troubleshooting section
2. Verify logs with `docker-compose logs [service]`
3. Open an issue in the repository with:
   - Detailed description of the problem
   - Commands executed
   - Relevant logs
   - Screenshots (if applicable)

---

â­ **If you find this project useful, please give it a star on GitHub!**