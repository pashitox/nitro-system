# ğŸš€ Proyecto Nitro - Sistema de Monitoreo Predictivo Industrial

## ğŸ“‹ Tabla de Contenidos
1. [CaracterÃ­sticas](#-caracterÃ­sticas)
2. [Arquitectura del Sistema](#-arquitectura-del-sistema)
3. [Servicios y Puertos](#-servicios-y-puertos)
4. [Quick Start](#-quick-start)
5. [Estructura del Proyecto](#-estructura-del-proyecto)
6. [Notebooks de AnÃ¡lisis](#-notebooks-de-anÃ¡lisis)
7. [Flujo de Datos](#-flujo-de-datos)
8. [TecnologÃ­as Implementadas](#-tecnologÃ­as-implementadas)
9. [Mantenimiento](#-mantenimiento)
10. [Troubleshooting](#-troubleshooting)

## âœ¨ CaracterÃ­sticas

- ğŸ“Š **Ingesta de datos en tiempo real** con Kafka Producer
- âš¡ **Procesamiento distribuido** con Spark Streaming
- ğŸ”§ **OrquestaciÃ³n inteligente** con Apache Airflow
- ğŸ’¾ **Almacenamiento escalable** en PostgreSQL y MinIO
- ğŸ¤– **MLOps avanzado** con MLflow y SHAP
- ğŸ“ˆ **VisualizaciÃ³n profesional** con Streamlit y Grafana
- ğŸ““ **AnÃ¡lisis exhaustivo** con notebooks especializados
- ğŸ” **Monitoreo en tiempo real** con dashboards interactivos

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
graph LR
A[Kafka Producer] --> B[Kafka Cluster]
B --> C[Spark Processor]
C --> D[(PostgreSQL)]
C --> E[MinIO Storage]
D --> F[FastAPI ML Service]
E --> F
F --> G[Streamlit Dashboard]
F --> H[Grafana Monitoring]
D --> H
```

## ğŸŒ Servicios y Puertos

| Servicio | URL | Puerto | Credenciales | Estado |
|----------|-----|--------|--------------|--------|
| ğŸ”§ **Airflow** | http://localhost:8080 | 8080 | admin/admin | âœ… Operativo |
| âš¡ **Spark Master** | http://localhost:8081 | 8081 | - | âœ… Operativo |
| ğŸ“Š **Streamlit Dashboard** | http://localhost:8501 | 8501 | - | âœ… Operativo |
| ğŸ“ˆ **Grafana** | http://localhost:3000 | 3000 | admin/admin123 | âœ… Operativo |
| ğŸ’¾ **MinIO Console** | http://localhost:9001 | 9001 | admin/admin12345 | âœ… Operativo |
| ğŸ—„ï¸ **PostgreSQL** | localhost:5432 | 5432 | nitro_user/nitro_pass | âœ… Operativo |
| ğŸš€ **FastAPI** | http://localhost:8000 | 8000 | - | âœ… Operativo |
| ğŸ“¡ **Kafka** | localhost:9092 | 9092/29092 | - | âœ… Operativo |

## ğŸš€ Quick Start

```bash
# Clonar el repositorio
git clone <tu-repositorio>
cd proyecto-nitro

# Iniciar todos los servicios
docker-compose up -d

# Verificar el estado de los servicios
docker-compose ps

# Iniciar el productor de datos
./start-producer.sh

# Acceder a los dashboards (esperar 2-3 minutos para inicializaciÃ³n completa)
echo "Accesos:"
echo "Airflow: http://localhost:8080"
echo "Grafana: http://localhost:3000"
echo "Streamlit: http://localhost:8501"
```

## ğŸ“ Estructura del Proyecto

```
proyecto-nitro/
â”œâ”€â”€ ğŸ“Š airflow/                 # DAGs y configuraciÃ³n de Airflow
â”œâ”€â”€ ğŸš€ api-dashboard/           # FastAPI y Streamlit
â”‚   â”œâ”€â”€ fastapi/               # API de predicciones ML
â”‚   â””â”€â”€ dashboards/            # Dashboards interactivos
â”œâ”€â”€ ğŸ“¡ kafka-producer/          # Productor de datos Kafka
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ kafka_producer.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ—„ï¸ minio-setup/             # ConfiguraciÃ³n de buckets MinIO
â”œâ”€â”€ ğŸ““ notebooks/              # AnÃ¡lisis y modelado
â”‚   â”œâ”€â”€ ğŸ“Š EDA.ipynb
â”‚   â”œâ”€â”€ âš™ï¸ feature_engineering.ipynb
â”‚   â”œâ”€â”€ ğŸ¤– model_training.ipynb
â”‚   â”œâ”€â”€ ğŸ” mlflow_tracking.ipynb
â”‚   â”œâ”€â”€ ğŸ“ˆ SHAP_analysis.ipynb
â”‚   â”œâ”€â”€ ğŸ“‹ reports/
â”‚   â”œâ”€â”€ ğŸ§  models/
â”‚   â””â”€â”€ ğŸ’¾ data/
â”‚       â””â”€â”€ enhanced_predictions.csv
â”œâ”€â”€ ğŸ—ƒï¸ postgres-setup/          # Esquemas y config de PostgreSQL
â”œâ”€â”€ âš¡ python-processor/        # Procesador de datos Spark
â”œâ”€â”€ ğŸ”¥ spark-processing/       # Jobs de Spark
â”œâ”€â”€ ğŸ³ docker-compose.yml      # OrquestaciÃ³n de contenedores
â”œâ”€â”€ ğŸš€ start-producer.sh       # Script de inicio
â””â”€â”€ ğŸ“– README.md              # Este archivo
```

## ğŸ““ Notebooks de AnÃ¡lisis

| Notebook | DescripciÃ³n | TecnologÃ­as |
|----------|-------------|-------------|
| ğŸ“Š `EDA.ipynb` | AnÃ¡lisis exploratorio de datos | Pandas, Matplotlib, Seaborn |
| âš™ï¸ `feature_engineering.ipynb` | IngenierÃ­a de caracterÃ­sticas | Scikit-learn, Featuretools |
| ğŸ¤– `model_training.ipynb` | Entrenamiento de modelos predictivos | Scikit-learn, XGBoost, MLflow |
| ğŸ” `mlflow_tracking.ipynb` | Seguimiento de experimentos ML | MLflow, Hyperopt |
| ğŸ“ˆ `SHAP_analysis.ipynb` | Explicabilidad de modelos | SHAP, Matplotlib |

## ğŸ”„ Flujo de Datos

1. **Ingesta**: Kafka Producer genera datos simulados de sensores industriales
2. **Streaming**: Kafka publica en el topic `sensor_topic` con 1 particiÃ³n
3. **Procesamiento**: Spark procesa los datos en tiempo real con transformations
4. **Almacenamiento**: Datos persistidos en PostgreSQL (estructurado) y MinIO (raw)
5. **AnÃ¡lisis**: Notebooks especializados para EDA y modelado predictivo
6. **VisualizaciÃ³n**: Dashboards en tiempo real con Streamlit y Grafana
7. **PredicciÃ³n**: FastAPI sirve modelos ML para mantenimiento predictivo

## ğŸ› ï¸ TecnologÃ­as Implementadas

### ğŸ—ï¸ Data Engineering
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)
![MinIO](https://img.shields.io/badge/MinIO-FF0019?style=for-the-badge&logo=minio&logoColor=white)

### ğŸ¤– Machine Learning
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)
![SHAP](https://img.shields.io/badge/SHAP-FF6B6B?style=for-the-badge)

### ğŸ“Š VisualizaciÃ³n & Monitoring
![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)

### ğŸ³ Infraestructura
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Docker Compose](https://img.shields.io/badge/Docker%20Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)

## ğŸ› ï¸ Mantenimiento

### Comandos Ãštiles
```bash
# Ver logs de todos los servicios
docker-compose logs

# Ver logs especÃ­ficos de un servicio
docker-compose logs kafka
docker-compose logs spark-master

# Reiniciar un servicio especÃ­fico
docker-compose restart kafka-producer

# Ver estado de los contenedores
docker-compose ps

# Acceder a PostgreSQL
docker-compose exec postgres psql -U nitro_user -d nitro_db

# Listar topics de Kafka
docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Escalar workers de Spark
docker-compose up -d --scale spark-worker=3
```

## ğŸ› Troubleshooting

### Problemas Comunes y Soluciones

| Problema | SoluciÃ³n |
|----------|----------|
| Kafka no inicia | Verificar que Zookeeper estÃ© saludable: `docker-compose logs zookeeper` |
| Producer no conecta | Esperar 30-60 segundos para inicializaciÃ³n completa de Kafka |
| PostgreSQL connection refused | Verificar logs: `docker-compose logs postgres` |
| Dashboards no cargan | Esperar 2-3 minutos y verificar que todos los servicios estÃ©n UP |
| Airflow webserver error | Ejecutar: `docker-compose restart airflow` |

### Limpieza y ReinstalaciÃ³n
```bash
# Detener y eliminar todos los contenedores y volÃºmenes
docker-compose down -v

# Reconstruir e iniciar todos los servicios
docker-compose up -d --build

# Forzar recreaciÃ³n de contenedores
docker-compose up -d --force-recreate
```

## ğŸ“Š Dashboard de Grafana - ConfiguraciÃ³n Recomendada

Para configurar Grafana con tus datos de PostgreSQL:

1. Accede a http://localhost:3000
2. Configura la fuente de datos PostgreSQL:
   - Host: `postgres:5432`
   - Database: `nitro_db`
   - User: `nitro_user`
   - Password: `nitro_pass`
3. Importa dashboards para:
   - Monitoring de Kafka (lag, throughput)
   - MÃ©tricas de rendimiento de Spark
   - AnÃ¡lisis de predicciones del modelo ML
   - Estado de salud de sensores en tiempo real

## ğŸ“ Licencia

MIT License - ver archivo LICENSE para detalles.

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! 

```bash
# 1. Haz fork del proyecto
# 2. Crea tu feature branch
git checkout -b feature/AmazingFeature

# 3. Commit tus cambios
git commit -m 'Add some AmazingFeature'

# 4. Push al branch
git push origin feature/AmazingFeature

# 5. Abre un Pull Request
```

## ğŸ“ Soporte

Si encuentras problemas:
1. Revisa la secciÃ³n de Troubleshooting
2. Verifica los logs con `docker-compose logs [servicio]`
3. Abre un issue en el repositorio con:
   - DescripciÃ³n detallada del problema
   - Comandos ejecutados
   - Logs relevantes
   - Capturas de pantalla (si aplica)

---

â­ **Â¡Si este proyecto te resulta Ãºtil, por favor dale una estrella en GitHub!**


